{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AI Impact on Jobs 2030\n",
        "Predicting automation risk across global professions by 2030.\n",
        "\n",
        "https://www.kaggle.com/datasets/khushikyad001/ai-impact-on-jobs-2030"
      ],
      "metadata": {
        "id": "gyW4pMjGZ0Q3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instala√ß√£o de depend√™ncias\n",
        "!pip install pandas openai python-dotenv kaggle -q\n",
        "!pip install google-generativeai -q  # Opcional para Gemini"
      ],
      "metadata": {
        "id": "0FETL6pE7o5G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81yhW71qrOTn"
      },
      "outputs": [],
      "source": [
        "# Importa√ß√£o de bibliotecas\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import requests\n",
        "import os\n",
        "import json\n",
        "import time\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Para exibir DataFrames de forma mais bonita\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "print(\"‚úÖ Bibliotecas importadas com sucesso!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. EXTRACT - Extra√ß√£o dos Dados"
      ],
      "metadata": {
        "id": "JomSOOcs77BQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Se n√£o quiser usar Kaggle API, carregue o arquivo manualmente:\n",
        "from google.colab import files\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Ler o arquivo carregado\n",
        "for filename in uploaded.keys():\n",
        "    df = pd.read_csv(filename)\n",
        "    print(f\"Arquivo {filename} carregado com {len(df)} registros\")"
      ],
      "metadata": {
        "id": "wVQgP5u_bfWJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fun√ß√£o de extra√ß√£o\n",
        "def extract_data(filepath='/content/AI_Impact_on_Jobs_2030.csv'):\n",
        "    \"\"\"\n",
        "    Extrai dados do arquivo CSV\n",
        "    \"\"\"\n",
        "    try:\n",
        "        df = pd.read_csv(filepath)\n",
        "        print(f\"üìä Dados extra√≠dos: {df.shape[0]} linhas, {df.shape[1]} colunas\")\n",
        "        print(\"\\nüìã Colunas dispon√≠veis:\")\n",
        "        for col in df.columns:\n",
        "            print(f\"  - {col}\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Erro na extra√ß√£o: {e}\")\n",
        "        return None\n",
        "\n",
        "# Executar extra√ß√£o\n",
        "df_raw = extract_data()\n",
        "if df_raw is not None:\n",
        "    display(df_raw.head())"
      ],
      "metadata": {
        "id": "RTIAiu2z-QXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. PREPARA√á√ÉO - Configura√ß√£o da IA Generativa"
      ],
      "metadata": {
        "id": "zbbAaFWl-inI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Configurar OpenAI\n",
        "from openai import OpenAI\n",
        "import getpass\n",
        "\n",
        "# Inserir a chave da API de forma segura\n",
        "openai_api_key = getpass.getpass('üîë Digite sua OpenAI API Key: ')\n",
        "\n",
        "# Configurar cliente\n",
        "client = OpenAI(api_key=openai_api_key)\n",
        "\n",
        "# Testar conex√£o\n",
        "try:\n",
        "    test_response = client.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[{\"role\": \"user\", \"content\": \"Teste de conex√£o. Responda com 'OK'\"}],\n",
        "        max_tokens=10\n",
        "    )\n",
        "    print(\"‚úÖ OpenAI configurada com sucesso!\")\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Erro na configura√ß√£o da OpenAI: {e}\")"
      ],
      "metadata": {
        "id": "kHgMagxu-nhG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Oh9mW85Qknha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. TRANSFORM - Transforma√ß√£o com IA"
      ],
      "metadata": {
        "id": "ERWNlLacAa40"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fun√ß√£o para limpar dados\n",
        "def clean_data(df):\n",
        "    \"\"\"\n",
        "    Limpa e prepara os dados\n",
        "    \"\"\"\n",
        "    print(\"üßπ Iniciando limpeza dos dados...\")\n",
        "\n",
        "    # Criar c√≥pia\n",
        "    df_clean = df.copy()\n",
        "\n",
        "    # Renomear colunas para facilitar\n",
        "    df_clean.columns = [col.strip().replace(' ', '_').lower() for col in df_clean.columns]\n",
        "\n",
        "    # Verificar valores nulos\n",
        "    print(f\"\\nüîç Valores nulos por coluna (se tiver contagem):\")\n",
        "    null_counts = df_clean.isnull().sum()\n",
        "    for col, count in null_counts.items():\n",
        "        if count > 0:\n",
        "            print(f\"  - {col}: {count} nulos ({count/len(df_clean)*100:.1f}%)\")\n",
        "\n",
        "    # Remover colunas com muitos valores nulos (opcional)\n",
        "    threshold = 0.5  # 50% de valores nulos\n",
        "    cols_to_drop = [col for col in df_clean.columns if df_clean[col].isnull().mean() > threshold]\n",
        "    if cols_to_drop:\n",
        "        print(f\"\\nüóëÔ∏è  Removendo colunas com >{threshold*100}% nulos: {cols_to_drop}\")\n",
        "        df_clean = df_clean.drop(columns=cols_to_drop)\n",
        "\n",
        "    # Identificar colunas de interesse\n",
        "    print(\"\\nüéØ Colunas identificadas:\")\n",
        "    job_cols = [col for col in df_clean.columns if 'job' in col or 'title' in col or 'occupation' in col]\n",
        "    score_cols = [col for col in df_clean.columns if 'impact' in col or 'score' in col or 'probability' in col]\n",
        "\n",
        "    print(f\"  - Colunas de cargo: {job_cols if job_cols else 'N√£o encontradas'}\")\n",
        "    print(f\"  - Colunas de score: {score_cols if score_cols else 'N√£o encontradas'}\")\n",
        "\n",
        "    return df_clean, job_cols, score_cols\n",
        "\n",
        "# Executar limpeza\n",
        "df_clean, job_cols, score_cols = clean_data(df_raw)\n",
        "display(df_clean.head())"
      ],
      "metadata": {
        "id": "iqLoabOmAcXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fun√ß√£o para gerar insights com IA\n",
        "\n",
        "\n",
        "def generate_ai_insight(job_title, impact_score, provider=\"openai\"):\n",
        "    \"\"\"\n",
        "    Gera insights sobre o impacto da IA em um cargo espec√≠fico\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Analise o impacto da Intelig√™ncia Artificial no cargo: {job_title}\n",
        "\n",
        "    Contexto:\n",
        "    - Score de impacto: {impact_score}/100 (quanto maior, maior o impacto)\n",
        "    - Horizonte temporal: 2030\n",
        "    - Setor: Tecnologia/Mercado de trabalho\n",
        "\n",
        "    Por favor, forne√ßa:\n",
        "    1. Uma breve an√°lise (2-3 frases) do impacto\n",
        "    2. 3 habilidades que ser√£o mais valorizadas\n",
        "    3. Recomenda√ß√£o: \"alta\", \"m√©dia\" ou \"baixa\" prioridade para requalifica√ß√£o\n",
        "\n",
        "    Formato a resposta como JSON:\n",
        "    {{\n",
        "        \"analise\": \"texto da an√°lise\",\n",
        "        \"habilidades\": [\"hab1\", \"hab2\", \"hab3\"],\n",
        "        \"prioridade\": \"alta/media/baixa\",\n",
        "        \"tendencia\": \"automatizado/transformado/expandido\"\n",
        "    }}\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        if provider == \"openai\":\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"Voc√™ √© um especialista em futuro do trabalho e IA. Responda em portugu√™s brasileiro.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0.7,\n",
        "                max_tokens=300\n",
        "            )\n",
        "            insight_text = response.choices[0].message.content\n",
        "\n",
        "        elif provider == \"gemini\":\n",
        "            response = gemini_model.generate_content(prompt)\n",
        "            insight_text = response.text\n",
        "\n",
        "        else:\n",
        "            insight_text = '{\"analise\": \"Insight n√£o dispon√≠vel\", \"habilidades\": [], \"prioridade\": \"media\", \"tendencia\": \"transformado\"}'\n",
        "\n",
        "        # Tentar extrair JSON da resposta\n",
        "        try:\n",
        "            # Encontrar texto entre chaves\n",
        "            start = insight_text.find('{')\n",
        "            end = insight_text.rfind('}') + 1\n",
        "            json_str = insight_text[start:end]\n",
        "            insight_json = json.loads(json_str)\n",
        "        except:\n",
        "            # Se n√£o for JSON v√°lido, criar estrutura padr√£o\n",
        "            insight_json = {\n",
        "                \"analise\": insight_text[:200] + \"...\" if len(insight_text) > 200 else insight_text,\n",
        "                \"habilidades\": [\"An√°lise de dados\", \"Pensamento cr√≠tico\", \"Adaptabilidade\"],\n",
        "                \"prioridade\": \"m√©dia\",\n",
        "                \"tendencia\": \"transformado\"\n",
        "            }\n",
        "\n",
        "        return insight_json\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Erro ao gerar insight: {e}\")\n",
        "        return {\n",
        "            \"analise\": f\"Erro na an√°lise: {str(e)[:100]}\",\n",
        "            \"habilidades\": [],\n",
        "            \"prioridade\": \"m√©dia\",\n",
        "            \"tendencia\": \"transformado\"\n",
        "        }"
      ],
      "metadata": {
        "id": "3J0-Xd8YA1KN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fun√ß√£o principal de transforma√ß√£o\n",
        "def transform_with_ai(df, job_cols, score_cols, sample_size=10, provider=\"openai\"):\n",
        "    \"\"\"\n",
        "    Adiciona insights gerados por IA ao DataFrame\n",
        "    \"\"\"\n",
        "    print(f\"ü§ñ Iniciando transforma√ß√£o com IA ({provider})...\")\n",
        "    print(f\"üìà Processando {sample_size} amostras...\")\n",
        "\n",
        "    # Criar c√≥pia\n",
        "    df_transformed = df.copy()\n",
        "\n",
        "    # Selecionar colunas para usar\n",
        "    job_col = job_cols[0] if job_cols else df.columns[0]\n",
        "    score_col = score_cols[0] if score_cols else df.columns[1] if len(df.columns) > 1 else df.columns[0]\n",
        "\n",
        "    print(f\"üîß Usando colunas: '{job_col}' e '{score_col}'\")\n",
        "\n",
        "    # Processar amostra\n",
        "    df_sample = df.head(sample_size).copy()\n",
        "\n",
        "    insights_list = []\n",
        "    habilidades_list = []\n",
        "    prioridades_list = []\n",
        "    tendencias_list = []\n",
        "\n",
        "    # Barra de progresso\n",
        "    from tqdm.notebook import tqdm\n",
        "\n",
        "    for idx, row in tqdm(df_sample.iterrows(), total=len(df_sample), desc=\"Gerando insights\"):\n",
        "        job_title = str(row[job_col])\n",
        "\n",
        "        # Tentar converter score para num√©rico\n",
        "        try:\n",
        "            impact_score = float(row[score_col])\n",
        "        except:\n",
        "            impact_score = 50  # Valor padr√£o\n",
        "\n",
        "        # Gerar insight\n",
        "        insight = generate_ai_insight(job_title, impact_score, provider)\n",
        "\n",
        "        insights_list.append(insight.get(\"analise\", \"\"))\n",
        "        habilidades_list.append(\", \".join(insight.get(\"habilidades\", [])))\n",
        "        prioridades_list.append(insight.get(\"prioridade\", \"m√©dia\"))\n",
        "        tendencias_list.append(insight.get(\"tendencia\", \"transformado\"))\n",
        "\n",
        "        # Pausa para evitar rate limit\n",
        "        time.sleep(1 if provider == \"openai\" else 0.5)\n",
        "\n",
        "    # Adicionar colunas ao DataFrame\n",
        "    df_sample['ai_insight'] = insights_list\n",
        "    df_sample['habilidades_futuras'] = habilidades_list\n",
        "    df_sample['prioridade_requalificacao'] = prioridades_list\n",
        "    df_sample['tendencia_2030'] = tendencias_list\n",
        "    df_sample['data_analise'] = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    print(\"‚úÖ Transforma√ß√£o com IA conclu√≠da!\")\n",
        "\n",
        "    return df_sample\n",
        "\n",
        "# Executar transforma√ß√£o\n",
        "df_transformed = transform_with_ai(df_clean, job_cols, score_cols,\n",
        "                                   sample_size=5, provider=\"openai\")\n",
        "\n",
        "# Mostrar resultados\n",
        "display(df_transformed[[job_cols[0] if job_cols else df_clean.columns[0],\n",
        "                       score_cols[0] if score_cols else df_clean.columns[1],\n",
        "                       'ai_insight', 'habilidades_futuras']].head())"
      ],
      "metadata": {
        "id": "-UmH-idrA9bg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. VISUALIZA√á√ÉO - An√°lise dos Resultados"
      ],
      "metadata": {
        "id": "N-rdYQjxoLmP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import re\n",
        "from collections import Counter\n",
        "\n",
        "# Configurar estilo dos gr√°ficos\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Lista de stopwords em portugu√™s para filtrar\n",
        "STOPWORDS_PT = {\n",
        "    'a','o','as','os','um','uma','uns','umas',\n",
        "    'de','do','da','dos','das','em','no','na','nos','nas',\n",
        "    'para','por','per','pra','pro','com','sem','sob','sobre','entre',\n",
        "    'ao','√†','√†s','aos','pelo','pela','pelos','pelas',\n",
        "    'e','ou','mas','porque','pois','que','se','como','quando','onde','quanto',\n",
        "    'este','esta','estes','estas','isso','isto','aquele','aquela','aqueles','aquelas',\n",
        "    'eu','tu','ele','ela','n√≥s','vos','eles','elas',\n",
        "    'me','te','se','lhe','nos','vos','lhes',\n",
        "    'meu','minha','meus','minhas',\n",
        "    'teu','tua','teus','tuas',\n",
        "    'seu','sua','seus','suas',\n",
        "    'dela','dele','delas','deles',\n",
        "    'quem','qual','quais','cujo','cuja','cujos','cujas',\n",
        "    'todo','todos','toda','todas',\n",
        "    'muito','muita','muitos','muitas',\n",
        "    'pouco','pouca','poucos','poucas',\n",
        "    'algum','alguma','alguns','algumas',\n",
        "    'nenhum','nenhuma','nenhuns','nenhumas',\n",
        "    'cada','mesmo','mesma','mesmos','mesmas',\n",
        "    'tamb√©m','j√°','ainda','s√≥','n√£o','sim'\n",
        "}\n",
        "\n",
        "# Adicionar mais stopwords relacionadas ao contexto\n",
        "STOPWORDS_CONTEXT = {\n",
        "    'ia','intelig√™ncia','artificial',\n",
        "    'trabalho','emprego','ocupa√ß√£o','fun√ß√£o',\n",
        "    'tarefa','atividade','cargo','profiss√£o',\n",
        "    'automa√ß√£o','automatizado','automatizar',\n",
        "    '20230','2030','tend√™ncia','transformado',\n",
        "    'habilidades','futuras','impacto'\n",
        "}\n",
        "\n",
        "# Combinar todas as stopwords\n",
        "ALL_STOPWORDS = STOPWORDS_PT.union(STOPWORDS_CONTEXT)\n",
        "\n",
        "# Fun√ß√£o para limpar texto e remover stopwords\n",
        "def clean_text_for_wordcloud(text):\n",
        "    \"\"\"\n",
        "    Limpa texto removendo stopwords e caracteres especiais\n",
        "    \"\"\"\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    # Converter para min√∫sculas\n",
        "    text = text.lower()\n",
        "\n",
        "    # Remover caracteres especiais e n√∫meros, manter apenas letras e espa√ßos\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "    text = re.sub(r'\\d+', ' ', text)\n",
        "\n",
        "    # Remover stopwords\n",
        "    words = text.split()\n",
        "    filtered_words = [word for word in words if word not in ALL_STOPWORDS and len(word) > 2]\n",
        "\n",
        "    return ' '.join(filtered_words)\n",
        "\n",
        "# Fun√ß√£o para extrair palavras mais relevantes\n",
        "def extract_keywords(text, top_n=20):\n",
        "    \"\"\"\n",
        "    Extrai as palavras mais frequentes do texto limpo\n",
        "    \"\"\"\n",
        "    clean_text = clean_text_for_wordcloud(text)\n",
        "    words = clean_text.split()\n",
        "\n",
        "    # Contar frequ√™ncia\n",
        "    word_counts = Counter(words)\n",
        "\n",
        "    # Remover palavras muito curtas\n",
        "    word_counts = {word: count for word, count in word_counts.items() if len(word) > 3}\n",
        "\n",
        "    # Pegar as top_n palavras\n",
        "    top_words = dict(word_counts.most_common(top_n))\n",
        "\n",
        "    return top_words"
      ],
      "metadata": {
        "id": "ufvTjBaxvuzP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar visualiza√ß√µes\n",
        "fig, axes = plt.subplots(2, 2, figsize=(20, 10))\n",
        "\n",
        "# 1. Distribui√ß√£o de prioridades\n",
        "if 'prioridade_requalificacao' in df_transformed.columns:\n",
        "    priority_counts = df_transformed['prioridade_requalificacao'].value_counts()\n",
        "    colors = ['#FF6B6B', '#FFD166', '#06D6A0']  # Vermelho, Amarelo, Verde\n",
        "    priority_order = ['alta', 'm√©dia', 'baixa']\n",
        "\n",
        "    # Reordenar para garantir a ordem correta\n",
        "    priority_counts = priority_counts.reindex(priority_order, fill_value=0)\n",
        "\n",
        "    bars = axes[0,0].bar(priority_counts.index, priority_counts.values, color=colors[:len(priority_counts)])\n",
        "    axes[0,0].set_title('üìä Distribui√ß√£o de Prioridade de Requalifica√ß√£o', fontsize=14, fontweight='bold')\n",
        "    axes[0,0].set_ylabel('Quantidade de Cargos', fontsize=12)\n",
        "    axes[0,0].set_xlabel('Prioridade', fontsize=12)\n",
        "    axes[0,0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "    # Adicionar valores nas barras\n",
        "    for i, v in enumerate(priority_counts.values):\n",
        "        axes[0,0].text(i, v + 0.1, str(v), ha='center', fontweight='bold')\n",
        "\n",
        "    # Adicionar porcentagem\n",
        "    total = priority_counts.sum()\n",
        "    for i, v in enumerate(priority_counts.values):\n",
        "        percentage = (v / total) * 100\n",
        "        axes[0,0].text(i, v/2, f'{percentage:.1f}%', ha='center', va='center',\n",
        "                      color='white', fontweight='bold', fontsize=11)\n",
        "\n",
        "# 2. Distribui√ß√£o de tend√™ncias\n",
        "if 'tendencia_2030' in df_transformed.columns:\n",
        "    trend_counts = df_transformed['tendencia_2030'].value_counts()\n",
        "    trend_colors = ['#EF476F', '#118AB2', '#073B4C']  # Rosa, Azul, Azul escuro\n",
        "\n",
        "    # Explodir a fatia mais relevante\n",
        "    explode = [0.1 if i == trend_counts.idxmax() else 0 for i in trend_counts.index]\n",
        "\n",
        "    wedges, texts, autotexts = axes[0,1].pie(trend_counts.values,\n",
        "                                            labels=trend_counts.index,\n",
        "                                            autopct='%1.1f%%',\n",
        "                                            colors=trend_colors[:len(trend_counts)],\n",
        "                                            explode=explode,\n",
        "                                            startangle=90,\n",
        "                                            shadow=True)\n",
        "\n",
        "    axes[0,1].set_title('üìà Tend√™ncia dos Cargos em 2030', fontsize=14, fontweight='bold')\n",
        "\n",
        "    # Melhorar a apar√™ncia dos textos\n",
        "    for autotext in autotexts:\n",
        "        autotext.set_color('white')\n",
        "        autotext.set_fontweight('bold')\n",
        "        autotext.set_fontsize(10)\n",
        "\n",
        "# 3. Word Cloud ou Gr√°fico de Barras de Palavras-chave\n",
        "try:\n",
        "    # Tentar importar wordcloud\n",
        "    from wordcloud import WordCloud\n",
        "\n",
        "    # Combinar todos os insights\n",
        "    all_insights = ' '.join(df_transformed['ai_insight'].astype(str))\n",
        "\n",
        "    # Limpar texto\n",
        "    clean_insights = clean_text_for_wordcloud(all_insights)\n",
        "\n",
        "    if clean_insights.strip():  # Verificar se h√° texto limpo\n",
        "        # Criar wordcloud\n",
        "        wordcloud = WordCloud(width=500,\n",
        "                             height=400,\n",
        "                             background_color='white',\n",
        "                             colormap='viridis',  # Mudar para outro colormap se quiser\n",
        "                             max_words=50,\n",
        "                             stopwords=set(),  # J√° limpamos antes\n",
        "                             contour_width=1,\n",
        "                             contour_color='steelblue').generate(clean_insights)\n",
        "\n",
        "        axes[1,0].imshow(wordcloud, interpolation='bilinear')\n",
        "        axes[1,0].axis('off')\n",
        "        axes[1,0].set_title('‚òÅÔ∏è  Palavras-chave mais Frequentes nos Insights',\n",
        "                           fontsize=14, fontweight='bold', pad=20)\n",
        "\n",
        "        # REMOVER OU COMENTAR ESTAS LINHAS PARA TIRAR O QUADRO:\n",
        "        # axes[1,0].text(0.02, 0.98, 'Tamanho = Frequ√™ncia\\nCor = Relev√¢ncia',\n",
        "        #                transform=axes[1,0].transAxes,\n",
        "        #                fontsize=9, verticalalignment='top',\n",
        "        #                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
        "\n",
        "    else:\n",
        "        # Fallback: gr√°fico de barras das palavras mais frequentes\n",
        "        top_words = extract_keywords(all_insights, top_n=15)\n",
        "\n",
        "        if top_words:\n",
        "            words = list(top_words.keys())\n",
        "            counts = list(top_words.values())\n",
        "\n",
        "            bars = axes[1,0].barh(range(len(words)), counts)\n",
        "            axes[1,0].set_yticks(range(len(words)))\n",
        "            axes[1,0].set_yticklabels(words, fontsize=10)\n",
        "            axes[1,0].set_xlabel('Frequ√™ncia')\n",
        "            axes[1,0].set_title('üìä Palavras-chave mais Frequentes', fontsize=14, fontweight='bold')\n",
        "\n",
        "            # Colorir barras baseado na frequ√™ncia\n",
        "            cmap = plt.cm.viridis\n",
        "            for i, bar in enumerate(bars):\n",
        "                normalized_value = counts[i] / max(counts)\n",
        "                bar.set_color(cmap(normalized_value))\n",
        "        else:\n",
        "            axes[1,0].text(0.5, 0.5, 'Texto insuficiente\\npara an√°lise',\n",
        "                          ha='center', va='center', fontsize=12)\n",
        "            axes[1,0].set_title('Word Cloud n√£o dispon√≠vel', fontsize=14)\n",
        "\n",
        "except ImportError:\n",
        "    # Se wordcloud n√£o estiver instalado, usar gr√°fico de barras\n",
        "    all_insights = ' '.join(df_transformed['ai_insight'].astype(str))\n",
        "    top_words = extract_keywords(all_insights, top_n=15)\n",
        "\n",
        "    if top_words:\n",
        "        words = list(top_words.keys())\n",
        "        counts = list(top_words.values())\n",
        "\n",
        "        bars = axes[1,0].barh(range(len(words)), counts, color='#118AB2')\n",
        "        axes[1,0].set_yticks(range(len(words)))\n",
        "        axes[1,0].set_yticklabels(words, fontsize=10)\n",
        "        axes[1,0].set_xlabel('Frequ√™ncia')\n",
        "        axes[1,0].set_title('üìä Palavras-chave mais Frequentes (sem WordCloud)',\n",
        "                           fontsize=14, fontweight='bold')\n",
        "\n",
        "        # Adicionar valores nas barras\n",
        "        for i, (word, count) in enumerate(zip(words, counts)):\n",
        "            axes[1,0].text(count + 0.1, i, str(count), va='center', fontweight='bold')\n",
        "    else:\n",
        "        axes[1,0].text(0.5, 0.5, 'Instale: !pip install wordcloud',\n",
        "                      ha='center', va='center', fontsize=12)\n",
        "        axes[1,0].set_title('Word Cloud n√£o instalado', fontsize=14)\n",
        "\n",
        "# 4. Top habilidades do futuro\n",
        "if 'habilidades_futuras' in df_transformed.columns:\n",
        "    all_skills = []\n",
        "    for skills in df_transformed['habilidades_futuras']:\n",
        "        # Dividir por v√≠rgula e limpar\n",
        "        skill_list = [s.strip().lower() for s in str(skills).split(',')]\n",
        "        all_skills.extend(skill_list)\n",
        "\n",
        "    # Filtrar stopwords das habilidades\n",
        "    all_skills = [skill for skill in all_skills\n",
        "                  if skill not in ALL_STOPWORDS and len(skill) > 3]\n",
        "\n",
        "    # Contar habilidades\n",
        "    skill_counts = Counter(all_skills)\n",
        "\n",
        "    # Pegar top 10 habilidades\n",
        "    top_skills = skill_counts.most_common(10)\n",
        "\n",
        "    if top_skills:\n",
        "        skills_names = [skill[0].capitalize() for skill in top_skills]\n",
        "        skills_counts = [skill[1] for skill in top_skills]\n",
        "\n",
        "        # Criar gradiente de cores\n",
        "        cmap = plt.cm.coolwarm\n",
        "        colors = [cmap(i / len(skills_names)) for i in range(len(skills_names))]\n",
        "\n",
        "        bars = axes[1,1].barh(range(len(skills_names)), skills_counts, color=colors)\n",
        "        axes[1,1].set_yticks(range(len(skills_names)))\n",
        "        axes[1,1].set_yticklabels(skills_names, fontsize=10)\n",
        "        axes[1,1].set_xlabel('Frequ√™ncia', fontsize=12)\n",
        "        axes[1,1].set_title('üí° Top 10 Habilidades do Futuro',\n",
        "                           fontsize=14, fontweight='bold', pad=15)\n",
        "\n",
        "        # Adicionar valores nas barras\n",
        "        for i, (name, count) in enumerate(zip(skills_names, skills_counts)):\n",
        "            axes[1,1].text(count + 0.1, i, str(count), va='center',\n",
        "                          fontweight='bold', fontsize=10)\n",
        "\n",
        "        # Adicionar grade sutil\n",
        "        axes[1,1].grid(axis='x', alpha=0.3, linestyle='--')\n",
        "    else:\n",
        "        axes[1,1].text(0.5, 0.5, 'Habilidades n√£o\\nencontradas',\n",
        "                      ha='center', va='center', fontsize=12)\n",
        "        axes[1,1].set_title('Habilidades do Futuro', fontsize=14)\n",
        "\n",
        "# Ajustar layout\n",
        "plt.suptitle('üìà An√°lise do Impacto da IA nos Empregos - 2030',\n",
        "             fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5gOTRiexw0bB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. LOAD - Exporta√ß√£o dos Resultados"
      ],
      "metadata": {
        "id": "aTHWFiL4ogwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def export_results(df, output_format='csv'):\n",
        "    \"\"\"\n",
        "    Exporta os resultados transformados\n",
        "    \"\"\"\n",
        "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "    if output_format == 'csv':\n",
        "        filename = f'ai_jobs_analysis_{timestamp}.csv'\n",
        "        df.to_csv(filename, index=False, encoding='utf-8')\n",
        "        print(f\"üíæ CSV salvo como: {filename}\")\n",
        "\n",
        "        # Criar link para download\n",
        "        from IPython.display import FileLink\n",
        "        display(FileLink(filename))\n",
        "\n",
        "    elif output_format == 'excel':\n",
        "        filename = f'ai_jobs_analysis_{timestamp}.xlsx'\n",
        "        df.to_excel(filename, index=False)\n",
        "        print(f\"üíæ Excel salvo como: {filename}\")\n",
        "        display(FileLink(filename))\n",
        "\n",
        "    elif output_format == 'json':\n",
        "        filename = f'ai_jobs_analysis_{timestamp}.json'\n",
        "        df.to_json(filename, orient='records', indent=2, force_ascii=False)\n",
        "        print(f\"üíæ JSON salvo como: {filename}\")\n",
        "        display(FileLink(filename))\n",
        "\n",
        "    return filename\n",
        "\n",
        "# Exportar para m√∫ltiplos formatos\n",
        "print(\"üì§ Exportando resultados...\")\n",
        "csv_file = export_results(df_transformed, 'csv')\n",
        "# excel_file = export_results(df_transformed, 'excel')"
      ],
      "metadata": {
        "id": "hPREnfJjoiLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. RESUMO EXECUTIVO COM IA"
      ],
      "metadata": {
        "id": "H-WYZ8zjpBPt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Gerar um resumo executivo dos resultados\n",
        "def generate_executive_summary(df, provider=\"openai\"):\n",
        "    \"\"\"\n",
        "    Gera um resumo executivo com base na an√°lise\n",
        "    \"\"\"\n",
        "\n",
        "    # Preparar dados para o prompt\n",
        "    if 'prioridade_requalificacao' in df.columns:\n",
        "        high_priority = (df['prioridade_requalificacao'] == 'alta').sum()\n",
        "        total_jobs = len(df)\n",
        "        percent_high = (high_priority / total_jobs) * 100\n",
        "\n",
        "    summary_prompt = f\"\"\"\n",
        "    Com base na an√°lise de {len(df)} cargos e seu impacto pela IA at√© 2030, gere um resumo executivo.\n",
        "\n",
        "    Estat√≠sticas principais:\n",
        "    - Total de cargos analisados: {len(df)}\n",
        "    - Cargos com alta prioridade de requalifica√ß√£o: {high_priority} ({percent_high:.1f}%)\n",
        "    - Tend√™ncia predominante: {df['tendencia_2030'].mode()[0] if 'tendencia_2030' in df.columns else 'N/A'}\n",
        "\n",
        "    Por favor, forne√ßa um resumo em portugu√™s brasileiro com:\n",
        "    1. Vis√£o geral dos impactos\n",
        "    2. Recomenda√ß√µes estrat√©gicas para RH/Governo\n",
        "    3. 3 a√ß√µes priorit√°rias\n",
        "\n",
        "    Formato o texto de forma profissional para tomadores de decis√£o.\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        if provider == \"openai\":\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-3.5-turbo\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"Voc√™ √© um consultor estrat√©gico de futuro do trabalho.\"},\n",
        "                    {\"role\": \"user\", \"content\": summary_prompt}\n",
        "                ],\n",
        "                temperature=0.7,\n",
        "                max_tokens=500\n",
        "            )\n",
        "            summary = response.choices[0].message.content\n",
        "\n",
        "        elif provider == \"gemini\":\n",
        "            response = gemini_model.generate_content(summary_prompt)\n",
        "            summary = response.text\n",
        "        else:\n",
        "            summary = \"Resumo executivo n√£o dispon√≠vel.\"\n",
        "\n",
        "        return summary\n",
        "\n",
        "    except Exception as e:\n",
        "        return f\"Erro ao gerar resumo: {str(e)}\"\n",
        "\n",
        "# Gerar e exibir resumo\n",
        "print(\"üìù Gerando resumo executivo...\")\n",
        "executive_summary = generate_executive_summary(df_transformed, \"openai\")\n",
        "\n",
        "display(Markdown(\"## üìä RESUMO EXECUTIVO DA AN√ÅLISE\"))\n",
        "display(Markdown(executive_summary))"
      ],
      "metadata": {
        "id": "QdGeroc0pAWo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}